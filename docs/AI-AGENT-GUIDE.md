# Guide for AI Coding Agents

**Purpose:** Help AI assistants work effectively by learning from past decisions, failures, and discoveries.

---

## ðŸš€ Quick Start (Read These FIRST)

### Before Writing Any Code
âœ… Check decisions: Does ADR exist for this approach?
âœ… Check failures: Has this been tried and failed before?
âœ… Check data-quirks: Any non-obvious data behavior?

**Commands to run:**
```bash
# Search for related decisions
grep -ri "keyword" docs/decisions/

# Search for past failures
grep -ri "keyword" docs/failures/

# Search for data quirks
grep -ri "keyword" docs/data-quirks/

# Search for integration patterns
grep -ri "keyword" docs/integrations/
```

---

## ðŸ“š Knowledge Base Structure

```
docs/
â”œâ”€â”€ decisions/           # Architecture Decision Records (ADRs)
â”œâ”€â”€ failures/            # Lessons learned (what NOT to do)
â”œâ”€â”€ data-quirks/         # Non-obvious data behavior
â”œâ”€â”€ integrations/        # External system gotchas
â””â”€â”€ AI-AGENT-GUIDE.md   # This file
```

---

## ðŸ¤– Compounding Engineering: Your Role

**What is it?**
> You don't just write code - you **compound knowledge** for future developers/agents by documenting decisions, failures, and discoveries.

**Your mission:**
1. âœ… Write code (normal development)
2. âœ… **PLUS:** Document what you learned for the next developer/agent

**Think:**
"Six months from now, someone (human or AI) will work on this. What do they need to know to avoid my mistakes and build on my success?"

---

## ðŸ“ When to Create Documentation (Auto-Compound)

### 1. Made an Architectural Decision? â†’ Create ADR

**Trigger conditions:**
- âœ… Chose between 2+ implementation approaches
- âœ… Selected a library/framework
- âœ… Decided on data structure or pattern
- âœ… Changed core Clean Architecture layer interaction
- âœ… Chose design pattern (Strategy, Factory, etc.)
- âœ… Selected external service provider

**Action:**
```bash
cp docs/decisions/000-template.md docs/decisions/00X-your-decision.md
```

**Fill in:**
- **Context:** Why was this decision needed?
- **Problem:** What are you solving?
- **Decision:** What did you choose?
- **Consequences:** Pros/cons, tradeoffs
- **Alternatives:** What you rejected and WHY

**Examples:**
- Chose Ollama over OpenAI for embeddings â†’ Create ADR
- Selected OptimizedHierarchicalChunking over SemanticChunking â†’ Create ADR
- Decided to use Clean Architecture â†’ Create ADR
- Chose ChromaDB over Qdrant â†’ Create ADR

---

### 2. Discovered Data Behaves Weirdly? â†’ Create Data Quirk Doc

**Trigger conditions:**
- âœ… Data format different than expected
- âœ… Table/collection has retention policy
- âœ… Field has NULL/invalid values unexpectedly
- âœ… Non-obvious relationships between entities
- âœ… Timezone/encoding inconsistencies
- âœ… API returns data in unexpected format

**Action:**
```bash
touch docs/data-quirks/00X-quirk-name.md
```

**Document:**
- **Behavior:** What's weird about the data?
- **Why it matters:** Impact on features/functionality
- **Root cause:** Why is it this way?
- **Detection:** How to identify this quirk
- **Correct patterns:** How to handle it properly

**Examples:**
- Ollama context window defaults to 2048 (not model max) â†’ Document quirk
- ChromaDB embedding dimension must match exactly â†’ Document quirk
- BM25 index requires manual refresh after updates â†’ Document quirk
- mxbai-embed-large optimal batch size is 5-8 â†’ Document quirk

---

### 3. Hit an Error or Made a Mistake? â†’ Create Failure Log

**Trigger conditions:**
- âœ… Assumed something that was wrong
- âœ… Built feature that didn't work (later fixed)
- âœ… Used wrong approach (wasted >1 hour)
- âœ… Discovered anti-pattern
- âœ… Integration failed in unexpected way
- âœ… Performance issue not anticipated

**Action:**
```bash
cp docs/failures/000-template.md docs/failures/00X-failure-name.md
```

**Document:**
- **What happened:** The mistake/error
- **Root cause:** Why it happened
- **Impact:** Consequences (time wasted, bugs, etc.)
- **Lessons learned:** What NOT to do
- **Resolution:** How it was fixed
- **Prevention:** Checklist to avoid in future

**Examples:**
- Race condition in concurrent evaluation submissions â†’ Document failure
- Ollama tests failed in CI (no Ollama instance) â†’ Document failure
- Used incremental counting with async operations â†’ Document failure
- Assumed embedding batch size of 32 would work (OOM) â†’ Document failure

---

### 4. Integrated External System? â†’ Create Integration Doc

**Trigger conditions:**
- âœ… Connected to new API/service
- âœ… Vendor-specific quirks discovered
- âœ… Authentication/authorization setup
- âœ… Error handling patterns established
- âœ… Rate limits/quotas encountered

**Action:**
```bash
touch docs/integrations/system-name.md
```

**Document:**
- **Purpose:** What does this integration do?
- **Authentication:** How to authenticate
- **Data format/schema:** Request/response structure
- **Quirks and gotchas:** Vendor-specific oddities
- **Error handling:** How to handle failures
- **Rate limits:** Throttling, quotas, retries

**Examples:**
- Ollama API integration â†’ Document patterns
- Document Processor API integration â†’ Document quirks
- ChromaDB integration â†’ Document edge cases
- SQLite async patterns â†’ Document best practices

---

## ðŸ” Before Implementing Features

### Step 1: Search Existing Knowledge

**Always run these searches before implementing:**

```bash
# Check if decision already made
grep -ri "authentication" docs/decisions/
grep -ri "chunking" docs/decisions/

# Check for past failures
grep -ri "race condition" docs/failures/
grep -ri "timeout" docs/failures/

# Check for data quirks
grep -ri "embedding" docs/data-quirks/
grep -ri "context window" docs/data-quirks/

# Check integration patterns
grep -ri "ollama" docs/integrations/
```

### Step 2: Check with User if Uncertain

**If you're not sure:**
- âœ… ASK the user before building
- âŒ DON'T assume and waste time

**Questions to ask:**
- "I see ADR-003 chose ChromaDB. Should I use the same approach?"
- "Failure-001 shows concurrent counting failed. Should I re-query DB instead?"
- "Data-Quirk-001 says context window defaults to 2048. Should I set num_ctx explicitly?"

---

## ðŸ”„ After You're Done

### Before Committing Code

**Checklist:**
- [ ] Did you make an architectural decision? â†’ Create ADR
- [ ] Did you discover data quirk? â†’ Document it
- [ ] Did you hit an error/mistake? â†’ Create failure log
- [ ] Did you integrate external system? â†’ Document patterns
- [ ] Did you learn something non-obvious? â†’ Document it

### During Code Review

**Ask yourself:**
- "Will the next developer understand WHY I made this choice?"
- "If this fails in production, will logs point to the quirk documentation?"
- "Did I search docs/ before implementing, or reinvent the wheel?"

---

## ðŸ“‹ Project-Specific Context

### This RAG Application

**Architecture:** Clean Architecture (Domain â†’ Ports â†’ Use Cases â†’ Adapters â†’ API)

**Key technologies:**
- **LLM/Embeddings:** Ollama (remote Cloud Run instances)
- **Vector Store:** ChromaDB
- **Search:** Hybrid (Vector + BM25 + Rank Fusion)
- **Database:** SQLite with async SQLAlchemy
- **Document Processing:** Remote spaCy Layout API

**Common patterns:**
- Use port interfaces (ABC/Protocol) for all external dependencies
- Services instantiated once at startup (`app.state`)
- Dependency injection via `app/api/deps.py`
- Background tasks for long-running operations
- Async operations for all I/O

**Known quirks:**
- Ollama context window defaults to 2048 (must set `num_ctx`)
- Embedding batch size 5-8 optimal for 16GB RAM
- ChromaDB telemetry must be disabled (`CHROMA_TELEMETRY=0`)
- BM25 index persists separately from vector store

### Search Before You Code

**Before implementing a use case:**
```bash
grep -ri "use case name" docs/decisions/
```

**Before choosing a library:**
```bash
grep -ri "library name" docs/decisions/
grep -ri "library name" docs/failures/
```

**Before implementing retrieval logic:**
```bash
grep -ri "retrieval" docs/decisions/
grep -ri "search" docs/data-quirks/
```

---

## ðŸŽ¯ Your Goal as AI Agent

**Not just:** Write working code

**But also:** Leave knowledge for the next developer/agent

**Success metrics:**
1. âœ… Code works
2. âœ… Tests pass
3. âœ… **Future developer avoids your mistakes** (documented in failures/)
4. âœ… **Future developer understands your decisions** (documented in decisions/)
5. âœ… **Future developer handles edge cases** (documented in data-quirks/)

---

## ðŸš¨ Anti-Patterns (DON'T DO THIS)

**âŒ Don't:**
- Implement feature without checking docs/ first
- Make architectural decision without creating ADR
- Hit error >1hr and not document failure
- Discover quirk and not document it
- Assume previous developer had no reason for choice

**âœ… Do:**
- Search docs/ before every implementation
- Create ADR for every non-trivial decision
- Document every failure that wasted time
- Document every surprising behavior
- Read existing ADRs to understand "why"

---

## ðŸ“– Example Workflow

### Scenario: Add new chunking strategy

1. **Search first:**
```bash
grep -ri "chunking" docs/decisions/
# Found: ADR-007 chose OptimizedHierarchicalChunking
# Reason: Preserves document structure, better retrieval
```

2. **Ask user:**
"ADR-007 chose OptimizedHierarchicalChunking. Should I extend it or create new strategy?"

3. **Implement based on decision**

4. **Document:**
```bash
# If architectural change
cp docs/decisions/000-template.md docs/decisions/008-semantic-chunking-addition.md

# If discovered quirk
touch docs/data-quirks/003-semantic-chunking-sentence-boundary.md
```

---

## ðŸ”— Quick Reference

**Templates:**
- ADR: `docs/decisions/000-template.md`
- Failure: `docs/failures/000-template.md`

**Search commands:**
```bash
# Find all decisions about X
grep -ri "keyword" docs/decisions/

# Find all failures related to Y
grep -ri "keyword" docs/failures/

# Find all quirks about Z
grep -ri "keyword" docs/data-quirks/
```

**When in doubt:**
1. Search docs/
2. Ask user
3. Document your decision

---

That's compounding engineering. Every session makes the next one faster. ðŸš€
