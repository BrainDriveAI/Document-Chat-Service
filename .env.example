# .env.example

###########################################################
# ðŸš€ Chat with your Documents App Configuration
###########################################################

# --- General Settings ---
# Set to 'true' for a more detailed log output, useful for debugging.
# DEBUG=False
# The host and port for the FastAPI application.
# API_HOST=0.0.0.0
# API_PORT=8000

# --- LLM and Embedding Providers ---
# Choose your LLM provider. Supported: openai, ollama, groq, openrouter
LLM_PROVIDER=ollama
# Choose your Embedding provider. Supported: openai, ollama
EMBEDDING_PROVIDER=ollama

# --- Ollama Configuration (if selected) ---
# Base URL for your Ollama server.
# Set to http://localhost:11434 if running locally.
OLLAMA_LLM_BASE_URL=http://host.docker.internal:11434
# The Ollama model to use for chat.
OLLAMA_LLM_MODEL=llama3.2:8b

OLLAMA_EMBEDDING_BASE_URL=http://host.docker.internal:11434
# The Ollama model to use for embeddings.
OLLAMA_EMBEDDING_MODEL=mxbai-embed-large

# EMBEDDING OPTIMIZATION
# You can tune these based on your hardware.
# For 16GB RAM: batch 8, concurrency 2 is usually safe.
# For 8GB RAM: batch 4, concurrency 1 is safer.
EMBEDDING_BATCH_SIZE=8
EMBEDDING_CONCURRENCY=2
EMBEDDING_TIMEOUT=120
EMBEDDING_MAX_RETRIES=3
EMBEDDING_RETRY_DELAY=2.0

# --- Contextual Retrieval (Advanced) ---
# If enabled, uses a separate, smaller LLM to generate chunk context
ENABLE_CONTEXTUAL_RETRIEVAL=true
OLLAMA_CONTEXTUAL_LLM_BASE_URL=http://host.docker.internal:11434
OLLAMA_CONTEXTUAL_LLM_MODEL=llama3.2:3b

# Reduce contextual processing load
CONTEXTUAL_BATCH_SIZE=3
CONTEXTUAL_CHUNK_TIMEOUT=60
CONTEXTUAL_DOC_MAX_LENGTH=4000

# --- Groq Configuration (if selected) ---
# Your Groq API key.
# GROQ_API_KEY=""
# The Groq model to use.
# GROQ_LLM_MODEL="llama3-70b-8192"

# --- Database & Storage Paths ---
# Directory for persistent data, including the database and files.
# UPLOADS_DIR=./data/uploads
# CHROMA_PERSIST_DIR=./data/vector_db
# BM25_PERSIST_DIR=./data/bm25_index
# SQLite database file path.
# DATABASE_URL="sqlite+aiosqlite:///./data/app.db"
# Example for PostgreSQL:
# DATABASE_URL="postgresql://user:password@host:port/dbname"

# --- Document Processing ---
# URL for the Document Processor microservice (BrainDrive-Document-AI).
# DOCUMENT_PROCESSOR_API_URL="https://your-document-processor.com"
DOCUMENT_PROCESSOR_API_URL=
DOCUMENT_PROCESSOR_API_KEY=
DOCUMENT_PROCESSOR_TIMEOUT=300
DOCUMENT_PROCESSOR_MAX_RETRIES=3

# Docker build
DOCKER_BUILDKIT=1
COMPOSE_DOCKER_CLI_BUILD=1
